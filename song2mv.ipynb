{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4045beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = unmasker(\"This course will teach you all about <mask> models.\", top_k=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ebcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "345/1500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7235c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c67dac",
   "metadata": {},
   "source": [
    "## Transformer架构\n",
    "* Whisper\n",
    "* ChatGLM3\n",
    "* SDXL\n",
    "## Moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebb8b8-4acc-4268-9e36-eb6a2e3fa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"medium\") #tiny, base, small, medium, large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10536190-4a9e-4107-a03b-3c27a74a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "songPath = \"翩翩\"\n",
    "song = songPath+\"/歌.mp3\"\n",
    "lyrics = songPath+\"/歌词.txt\" #根据segments调整\n",
    "timedlyrics = songPath+\"/时序歌词.srt\"\n",
    "result = model.transcribe(song,language='Chinese')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83e3f936",
   "metadata": {},
   "source": [
    "## 为了方便与原歌词(歌词.txt)对比, 然后合并歌词, 与原歌词长度对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e167375-5f31-4704-bfe7-d0281f083368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segments(segments, i):\n",
    "    i=i-1\n",
    "    segments[i]['text'] += segments[i+1]['text']\n",
    "    del segments[i+1]\n",
    "    for i in range(0,len(segments)-1):\n",
    "        segments[i]['end'] = segments[i+1]['start']\n",
    "    for i in range(0,len(segments)-1):\n",
    "        segments[i]['id'] = i+1    \n",
    " \n",
    "\n",
    "segments = [{'id': item['id']+1, 'start': item['start'], 'end': item['end'], 'text': item['text']} for item in result['segments']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76501d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_segments(segments,15)\n",
    "segments[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae794e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abaeb2f3",
   "metadata": {},
   "source": [
    "## 根据自动识别的歌词分段(text),手动调整歌词与text对应, 然后读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8928b85-6361-48f8-847c-b4abddecdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsegments = []\n",
    "\n",
    "with open(lyrics, 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        lsegments.append(line.strip())\n",
    "lsegments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aca339ac",
   "metadata": {},
   "source": [
    "## text1为调整后的歌词,与自动识别的歌词(text)对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ddc93-5d43-4a3d-876e-fb2a037f2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(segments)):\n",
    "    segments[i]['text1'] = lsegments[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f01173",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(timedlyrics, \"w\") as file:\n",
    "    for i, segment in enumerate(segments):\n",
    "        start_time = segment['start']\n",
    "        end_time = segment['end']\n",
    "        text = segment['text1']\n",
    "        \n",
    "        file.write(f\"{i+1}\\n\")\n",
    "        file.write(f\"{start_time} --> {end_time}\\n\")\n",
    "        file.write(f\"{text}\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca4c88b",
   "metadata": {},
   "source": [
    "## 根据歌词text1生成图形提示词text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "llm_url = 'http://0.0.0.0:8000' #本地LLM API地址\n",
    "\n",
    "def prompt_generation(text1):\n",
    "    # 发送HTTP POST请求\n",
    "    \n",
    "    data = {'prompt':'根据下面的内容描述，生成一副生动的画面并只用英文表示：'+text1}\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # 发送HTTP POST请求\n",
    "    response = requests.post(llm_url, data=json_data, headers={'Content-Type': 'application/json'})\n",
    "    result_json = json.loads(response.text)\n",
    " \n",
    "    # 输出结果\n",
    "    if 'response' in result_json:\n",
    "        return result_json['response']\n",
    "    else:\n",
    "        print(\"Unexpected result:\", result_json)\n",
    "        return None\n",
    "\n",
    "for i in range(len(segments)):\n",
    "    segments[i]['text2'] = prompt_generation(segments[i]['text1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddeeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[-3:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c98650b",
   "metadata": {},
   "source": [
    "## 根据text2生成图片到images目录下\n",
    "novel_dict对sdxl要从新调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f160e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_url = \"http://127.0.0.1:7860/sdapi/v1/txt2img\"\n",
    "prompt = \"best quality,masterpiece,illustration, an extremely delicate and beautiful,extremely detailed,CG,unity,8k wallpaper, \"\n",
    "negative =\"NSFW,sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ((grayscale)), skin spots, acnes, skin blemishes, bad anatomy,(long hair:1.4),DeepNegative,(fat:1.2),facing away, looking away,tilted head, {Multiple people}, lowres,bad anatomy,bad hands, text, error, missing fingers,extra digit, fewer digits, cropped, worstquality, low quality, normal quality,jpegartifacts,signature, watermark, username,blurry,bad feet,cropped,poorly drawn hands,poorly drawn face,mutation,deformed,worst quality,low quality,normal quality,jpeg artifacts,signature,watermark,extra fingers,fewer digits,extra limbs,extra arms,extra legs,malformed limbs,fused fingers,too many fingers,long neck,cross-eyed,mutated hands,polar lowres,bad body,bad proportions,gross proportions,text,error,missing fingers,missing arms,missing legs,extra digit, extra arms, extra leg, extra foot,\"\n",
    "\n",
    "novel_dict = { #SD1.5\n",
    "          \"enable_hr\": \"false\",\n",
    "          \"denoising_strength\": 0,\n",
    "          \"firstphase_width\": 0,\n",
    "          \"firstphase_height\": 0,\n",
    "          \"hr_scale\": 2,\n",
    "          \"hr_upscaler\": \"string\",\n",
    "          \"hr_second_pass_steps\": 0,\n",
    "          \"hr_resize_x\": 0,\n",
    "          \"hr_resize_y\": 0,\n",
    "          \"prompt\": \"\",\n",
    "          \"styles\": [\"string\"],\n",
    "          \"seed\": -1,\n",
    "          \"subseed\": -1,\n",
    "          \"subseed_strength\": 0,\n",
    "          \"seed_resize_from_h\": -1,\n",
    "          \"seed_resize_from_w\": -1,\n",
    "          \"sampler_name\": \"DPM++ SDE Karras\",\n",
    "          \"batch_size\": 1,\n",
    "          \"n_iter\": 1,\n",
    "          \"steps\": 25,\n",
    "          \"cfg_scale\": 7,\n",
    "          \"width\":768,#1024\n",
    "          \"height\": 1024,#768\n",
    "          \"restore_faces\": \"false\",\n",
    "          \"tiling\": \"false\",\n",
    "          \"do_not_save_samples\": \"false\",\n",
    "          \"do_not_save_grid\": \"false\",\n",
    "          \"negative_prompt\": negative,\n",
    "          \"eta\": 0,\n",
    "          \"s_churn\": 0,\n",
    "          \"s_tmax\": 0,\n",
    "          \"s_tmin\": 0,\n",
    "          \"s_noise\": 1,\n",
    "          \"override_settings\": {},\n",
    "          \"override_settings_restore_afterwards\": \"true\",\n",
    "          \"script_args\": [],\n",
    "          \"sampler_index\": \"DPM++ SDE Karras\",\n",
    "          \"script_name\": \"\",\n",
    "          \"send_images\": \"true\",\n",
    "          \"save_images\": \"true\",\n",
    "          \"alwayson_scripts\": {}\n",
    "        }\n",
    "novel_dict2 = { #SDXL: \n",
    "    \"text_prompt\": \"\",\n",
    "    \"negative_prompt\": negative,\n",
    "    \"width\": 1344, #最大:1048576, 缺省:512\n",
    "    \"height\": 768,\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 7,\n",
    "    \"engine\":\"stable-diffusion-xl-1024-v1-0\", #缺省:stable-diffusion-xl-1024-v0-9\n",
    "    \"sampler\": \"UiPC\",#缺省: k_dpmpp_2m\n",
    "    #\"batch_size\": 1,\n",
    "    #\"n_iter\": 1,\n",
    "        \n",
    "    \"send_images\": \"true\",\n",
    "    \"save_images\": \"true\",\n",
    "}\n",
    "for i in range(1,len(segments)):\n",
    "    #novel_dict1['prompt']=prompt+segments[i]['text2']\n",
    "    novel_dict2['text_prompt']=prompt+segments[i]['text2']\n",
    "    \n",
    "    html = requests.post(sd_url, data=json.dumps(novel_dict2))\n",
    "    image_response = json.loads(html.text)\n",
    "    image_bytes = base64.b64decode(image_response['images'][0])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image_file = songPath+'/images/'+str(segments[i]['id'])+'.jpg'\n",
    "    image.save(image_file)\n",
    "    segments[i]['image_file'] = image_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "txt_speed = 4\n",
    "h=1024\n",
    "w=1024\n",
    "\n",
    "\n",
    "\n",
    "def fl_up(gf, t):\n",
    "    start = max(0, int(txt_speed*t))\n",
    "    end = min(int(txt_speed*t)+h, gf(t).shape[0])\n",
    "    return gf(t)[start:end, :]\n",
    "\n",
    "def fl_down(gf, t):\n",
    "    start = max(0, int(txt_speed*t)-h)\n",
    "    end = min(int(txt_speed*t), gf(t).shape[0])\n",
    "    return gf(t)[start:end, :]\n",
    "\n",
    "def fl_left(gf, t):\n",
    "    start = max(0, int(txt_speed*t))\n",
    "    end = min(int(txt_speed*t)+w, gf(t).shape[1])\n",
    "    return gf(t)[:, start:end]\n",
    "\n",
    "def fl_right(gf, t):\n",
    "    start = max(0, int(txt_speed*t)-w)\n",
    "    end = min(int(txt_speed*t), gf(t).shape[1])\n",
    "    return gf(t)[:, start:end]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fl_zoom(gf, t, start_scale=1.0, end_scale=1.2):\n",
    "    image = gf(t)\n",
    "    if image.size == 0:\n",
    "        print(f\"Empty image at time {t}\")\n",
    "        return image\n",
    "    scale = start_scale + (end_scale - start_scale) * t / duration\n",
    "    new_size = (int(image.shape[1] * scale), int(image.shape[0] * scale))\n",
    "    return cv2.resize(image, new_size)\n",
    "\n",
    "def fl_shrink(gf, t, start_scale=1.2, end_scale=1.0):\n",
    "    image = gf(t)\n",
    "    if image.size == 0:\n",
    "        print(f\"Empty image at time {t}\")\n",
    "        return image\n",
    "    scale = start_scale + (end_scale - start_scale) * t / duration\n",
    "    new_size = (int(image.shape[1] * scale), int(image.shape[0] * scale))\n",
    "    return cv2.resize(image, new_size)\n",
    "\n",
    "def center_zoom(gf, t, start_scale=1.0, end_scale=1.2):\n",
    "    image = gf(t)\n",
    "    if image.size == 0:\n",
    "        print(f\"Empty image at time {t}\")\n",
    "        return image\n",
    "    \n",
    "    scale = start_scale + (end_scale - start_scale) * t / duration\n",
    "    new_size = (int(image.shape[1] * scale), int(image.shape[0] * scale))\n",
    "    \n",
    "    # 计算平移量\n",
    "    dx = (image.shape[1] - new_size[0]) // 2\n",
    "    dy = (image.shape[0] - new_size[1]) // 2\n",
    "    \n",
    "    # 缩放图像\n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    \n",
    "    # 创建平移矩阵\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    \n",
    "    # 平移图像\n",
    "    zoomed_image = cv2.warpAffine(resized_image, M, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    return zoomed_image\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageClip, AudioFileClip, TextClip,VideoFileClip, concatenate_videoclips,CompositeVideoClip\n",
    "from moviepy.video import fx\n",
    "from moviepy.editor import vfx\n",
    "\n",
    "font = \"/System/Library/Fonts/PingFang.ttc\" \n",
    "clips = []\n",
    "# 定义动画函数列表\n",
    "fl_functions = [fl_up, fl_down, fl_left, fl_right, fl_zoom, fl_shrink]\n",
    "\n",
    "for ii in range(len(segments)):\n",
    "    image_file = segments[ii]['image_file']\n",
    "    duration = segments[ii]['end']-segments[ii]['start']\n",
    "    text1 = segments[ii]['text1']\n",
    "    fl = random.choice(fl_functions)\n",
    "    print(ii, image_file, duration,fl, text1)\n",
    "\n",
    "    image_clip = ImageClip(image_file)\n",
    "    image_clip = image_clip.set_duration(duration)  # 设置时长\n",
    "    \n",
    "\n",
    "    image_clip = image_clip.fl(fl_functions[i%6])\n",
    "  \n",
    "\n",
    "    text_clip = TextClip(text1,fontsize=54,font=font,color='yellow', bg_color='black')\n",
    "    #text_clip = text_clip.set_position(('center','bottom'))\n",
    "    text_clip = text_clip.set_position(('center',0.8), relative=True)\n",
    "    text_clip = text_clip.set_duration(duration)\n",
    "    text_clip = text_clip.set_opacity(0.6)\n",
    "    \n",
    "    composite_clip = CompositeVideoClip([image_clip, text_clip])\n",
    "    clips.append(composite_clip)\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "audio_clip = AudioFileClip(song)\n",
    "final_clip = final_clip.set_audio(audio_clip)\n",
    "final_clip.write_videofile(songPath+\"/歌.mp4\", fps=24, audio_codec=\"aac\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5748bf96",
   "metadata": {},
   "source": [
    "## 根据歌词片段,生成视频查询关键词"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "219b835d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b18614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "llm_url = 'http://0.0.0.0:8000' #本地LLM API地址\n",
    "\n",
    "sys='''system_prompt:\n",
    "  # Instructions\n",
    "\n",
    "  You're a video research expert. The user will give you the timed captions of a video they will make, and you will give back a list of couples of text search queries that will be used to search for background video footage, and the time t1 and t2 when it will be shown in the video.\n",
    "  # Output format\n",
    "  The format will be JSON parasable and look like this:\n",
    "  [[[0.0, 4.4], [\"Dog barking\", \"Dog angry\", Canine angry\"]], [[4.4, 7.8], \"bone\", \"pet food\", \"food\", \"canine\"], ect...\n",
    "\n",
    "  # Time periods t1 and t2\n",
    "  Time periods t1 and t2 must always be consecutive, and last between 4 to 5 seconds, and must cover the whole video.\n",
    "  For example, \t[0, 2.5] <= IS BAD, because 2.5-0 = 2.5 < 3\n",
    "              [0, 11]  <= IS BAD, because 11sec > 5 sec\n",
    "              [0, 4.2] <= IS GOOD\n",
    "              \n",
    "  # Query search string list\n",
    "  YOU ALWAYS USE ENGLISH IN YOUR TEXT QUERIES\n",
    "  As you have seen above, for each time period you will be tasked to generate 3 strings that will be searched on the video search engine, to find the appropriate clip to find.\n",
    "  Each string has to be between ONE to TWO words.\n",
    "  Each search string must DEPICT something visual.\n",
    "  The depictions have to be extremely visually concrete, like `coffee beans`, or `dog running`.\n",
    "  'confused feelings' \t\t\t<= BAD, because it doesn't depict something visually\n",
    "  'heartbroken man' \t\t\t<= GOOD, because it depicts something visual. \n",
    "  'man feeling very lonely' \t<= BAD, because it contains 4 words.\n",
    "  The list must always contain 3 query searches.\n",
    "  ['Sad person']\t\t\t\t\t<= BAD, because it's one string\n",
    "  ['Sad person', 'depressed man', 'depressed person'] <= GOOD, because it's 3 strings\n",
    "  ['Une Pomme', 'un enfant qui rit', 'une personne heureuse'] <= BAD, because the text query is NOT in english\n",
    "'''\n",
    "\n",
    "def words_generation(text1):\n",
    "    # 发送HTTP POST请求\n",
    "    \n",
    "    #data = {'system_prompt':sys,  'chat_prompt': \"Timed captions:\"+text1+\"Video search queries\"}\n",
    "    data = {'prompt':sys+'chat_prompt: Timed captions:'+text1+'Video search queries'}\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # 发送HTTP POST请求\n",
    "    response = requests.post(llm_url, data=json_data, headers={'Content-Type': 'application/json'})\n",
    "    result_json = json.loads(response.text)\n",
    " \n",
    "    # 输出结果\n",
    "    if 'response' in result_json:\n",
    "        return result_json['response']\n",
    "    else:\n",
    "        print(\"Unexpected result:\", result_json)\n",
    "        return None\n",
    "\n",
    "for i in range(len(segments)):\n",
    "    segments[i]['text3'] = words_generation(segments[i]['text1'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82dcc37b",
   "metadata": {},
   "source": [
    "## 根据歌词片段, 生成视频clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ac635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "\n",
    "def search_videos(query_string, landscape=True):\n",
    "    url = \"https://api.pexels.com/videos/search\"\n",
    "    headers = {\n",
    "        \"Authorization\":\"RQdKQPXlzy3URM55teyKcU5taQBPE5J9pFlh7WNG4tcQASjAz0Nkn5l6\"\n",
    "    }\n",
    "    params = {\n",
    "        \"query\": query_string,\n",
    "        \"orientation\": \"landscape\" if landscape else \"portrait\",\n",
    "        \"per_page\": 15\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    json_data = response.json()\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def getBestVideo(query_string, orientation_landscape=True, used_vids=[]):\n",
    "    vids = search_videos(query_string, orientation_landscape)\n",
    "    videos = vids['videos']  # Extract the videos list from JSON\n",
    "\n",
    "    # Filter and extract videos with width and height as 1920x1080 for landscape or 1080x1920 for portrait\n",
    "    if orientation_landscape:\n",
    "        filtered_videos = [video for video in videos if video['width'] >= 1920 and video['height'] >= 1080 and video['width']/video['height'] == 16/9]\n",
    "    else:\n",
    "        filtered_videos = [video for video in videos if video['width'] >= 1080 and video['height'] >= 1920 and video['height']/video['width'] == 16/9]\n",
    "\n",
    "    # Sort the filtered videos by duration in ascending order\n",
    "    sorted_videos = sorted(filtered_videos, key=lambda x: abs(15-int(x['duration'])))\n",
    "\n",
    "    # Extract the top 3 videos' URLs\n",
    "    for video in sorted_videos:\n",
    "        for video_file in video['video_files']:\n",
    "            if orientation_landscape:\n",
    "                if video_file['width'] == 1920 and video_file['height'] == 1080:\n",
    "                    if not (video_file['link'].split('.hd')[0] in used_vids):\n",
    "                        return video_file['link']\n",
    "            else:\n",
    "                if video_file['width'] == 1080 and video_file['height'] == 1920:\n",
    "                    if not (video_file['link'].split('.hd')[0] in used_vids):\n",
    "                        return video_file['link']\n",
    "    print(\"NO LINKS found for this round of search with query :\", query_string)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e274d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vurl=getBestVideo('sad eyes',1).split('&')[0]\n",
    "clip = VideoFileClip(vurl)\n",
    "clip.write_videofile('temp.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea9029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eefcf26",
   "metadata": {},
   "source": [
    "# 转换heic文件为jpg文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_heic_to_jpg(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".heic\"):\n",
    "            heic_file = os.path.join(directory, filename)\n",
    "            jpg_file = os.path.splitext(heic_file)[0] + \".jpg\"\n",
    "            ! magick convert {heic_file} {jpg_file}\n",
    "\n",
    "# 指定目录路径\n",
    "directory_path = \"/Users/xjq284/Pictures/xjq\"\n",
    "\n",
    "# 调用函数进行转换\n",
    "convert_heic_to_jpg(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def convert_heic_to_jpg(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".heic\"):\n",
    "            heic_file = os.path.join(directory, filename)\n",
    "            jpg_file = os.path.splitext(heic_file)[0] + \".jpg\"\n",
    "            \n",
    "        \n",
    "            \n",
    "            # 将HEIC图像转换为PIL图像对象\n",
    "            image = Image.open(heic_file)\n",
    "            \n",
    "            # 保存为JPG格式\n",
    "            image.save(jpg_file, \"JPEG\")\n",
    "            \n",
    "            # 删除原始的HEIC文件\n",
    "            os.remove(heic_file)\n",
    "\n",
    "# 指定目录路径\n",
    "directory_path = \"/Users/xjq284/Pictures/xjq\"\n",
    "\n",
    "# 调用函数进行转换\n",
    "convert_heic_to_jpg(directory_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd3797ed",
   "metadata": {},
   "source": [
    "# 录音5分钟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_wav_to_mp3(wav_file, mp3_file):\n",
    "    # 读取.wav文件\n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "\n",
    "    # 将音频导出为MP3格式\n",
    "    audio.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "def record_audio(duration, filename):\n",
    "    # 设置录音参数\n",
    "    sample_rate = 44100  # 采样率\n",
    "    channels = 1  # 声道数\n",
    "\n",
    "    # 开始录音\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels)\n",
    "\n",
    "    # 等待录音完成\n",
    "    sd.wait()\n",
    "\n",
    "    # 保存录音为.wav文件\n",
    "    wavfile.write(filename, sample_rate, recording)\n",
    "\n",
    "# 设置录音时长和保存文件名\n",
    "duration = 5*60  # 录音时长（秒）\n",
    "filename = \"recording\"  # 保存文件名\n",
    "\n",
    "wav_file = \"/Users/xjq284/myvoice/\"+filename+\".wav\"\n",
    "mp3_file = \"/Users/xjq284/myvoice/\"+filename+\".mp3\"\n",
    "\n",
    "# 调用录音函数\n",
    "record_audio(duration, wav_file)\n",
    "convert_wav_to_mp3(wav_file, mp3_file)\n",
    "os.remove(wav_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_wav_to_mp3(wav_file, mp3_file):\n",
    "    # 读取.wav文件\n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "\n",
    "    # 将音频导出为MP3格式\n",
    "    audio.export(mp3_file, format=\"mp3\")\n",
    "\n",
    "# 指定输入的.wav文件和输出的MP3文件\n",
    "wav_file = \"recording2.wav\"\n",
    "mp3_file = \"recording2.mp3\"\n",
    "\n",
    "# 调用函数进行转换\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d39ff587",
   "metadata": {},
   "source": [
    "从一个\"\n",
    "0:06\n",
    "关于权重和神经网络\n",
    "0:08\n",
    "权重是神经网络的参数\n",
    "0:10\n",
    "网络的参数\"格式文件读入, 然后以以下格式\"\n",
    "1\n",
    "0:06-->0:08\n",
    "关于权重和神经网络\n",
    "2\n",
    "0:08-->0:10\n",
    "权重是神经网络的参数\n",
    "3\n",
    "0:10-->0:12\n",
    "网络的参数\"\n",
    "写入另外一个文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca95b4d5",
   "metadata": {},
   "source": [
    "# 把youtube类型字幕转换为srt字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bff8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def format_time(time_str):\n",
    "    time_format = \"%M:%S\"\n",
    "    time_obj = datetime.strptime(time_str, time_format)\n",
    "    return time_obj.strftime(\"%H:%M:%S,%f\")[:-3]\n",
    "\n",
    "def convert_to_srt(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        content = file.read().strip().split('\\n')\n",
    "\n",
    "    srt = ''\n",
    "\n",
    "    for i in range(0, len(content)-2, 2):\n",
    "        start_time = format_time(content[i])\n",
    "        end_time = format_time(content[i+2])\n",
    "        if len(content[i+1]) > 1:\n",
    "            text = content[i+1]\n",
    "        else:\n",
    "            text = \"\"\n",
    "        srt += f\"{i//2+1}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(srt)\n",
    "\n",
    "# 指定输入文件和输出文件\n",
    "input_file = \"1.srt\"\n",
    "output_file = \"2.srt\"\n",
    "\n",
    "# 调用函数进行转换\n",
    "convert_to_srt(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
